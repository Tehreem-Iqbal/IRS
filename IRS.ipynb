{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 IRS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# required imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"1.png\"/>\n",
    "<img src=\"2.png\"/>\n",
    "<img src=\"3.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#You have to create few files with dummy data of your own choice as shown above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have intialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'f1.txt', 2: 'f2.txt', 3: 'f3.txt'}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "path = os.walk(\"C:/Users/tehre/Desktop/This/AI/IRS/myFiles\")\n",
    "i=1\n",
    "for root,directories, files in path:\n",
    "    for file in files:\n",
    "        files_dict[i] = file;\n",
    "        i+=1\n",
    "print(files_dict)\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "for key in files_dict:\n",
    "    file_count+=1\n",
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {1: 'f1.txt', 2: 'f2.txt', 3: 'f3.txt'}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of unique words:  {'my', 'very', 'pen', 'book', 'this', 'is', 'interesting'}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "for key in files_dict:\n",
    "    text_file = open(files_dict[key], 'r')\n",
    "    text = text_file.read()\n",
    "    text = text.strip(\",.\")\n",
    "    text_file.close()\n",
    "    #cleaning\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "            unique_word_set.add(word)\n",
    "print(\"Dictionary of unique words: \",unique_word_set)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"4.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Term doc matrix such that columns will be unique words and all the files will be rows\n",
    "\n",
    "# Write code to count all the unique words appearances in all the files and store it in a dictionary for words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term document matrix initially\n",
      " [[0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Dictionary of words\n",
      "{'my': 3, 'very': 1, 'pen': 1, 'book': 2, 'this': 2, 'is': 3, 'interesting': 1}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "\n",
    "TDM = np.zeros(( len(files_dict),len(unique_word_set)))\n",
    "print(\"Term document matrix initially\\n\",TDM)\n",
    "\n",
    "dic_of_words ={}\n",
    "for word in unique_word_set:\n",
    "    count =0\n",
    "    for file in files_dict:\n",
    "        text_file = open(files_dict[file], 'r')\n",
    "        text = text_file.read()\n",
    "        text = text.lower()\n",
    "        text = text.strip(\",.!''\")\n",
    "        words = text.split()\n",
    "        count +=words.count(word)\n",
    "    dic_of_words[word] = count\n",
    "\n",
    "print(\"\\nDictionary of words\")\n",
    "print(dic_of_words)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"5.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "# If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "# Do the same for all the files present in the directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Term Document Matrix after filling\n",
      " [[1. 0. 0. 1. 1. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 1. 0.]\n",
      " [1. 1. 0. 1. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "for file in files_dict:\n",
    "    text_file = open(files_dict[file], 'r')\n",
    "    text = text_file.read()\n",
    "    text = text.lower()\n",
    "    text= text.strip(\",.!''\")\n",
    "    words = text.split()\n",
    "    i = 0 \n",
    "    for word in unique_word_set:\n",
    "        if word in words:\n",
    "            TDM[file-1][i] = 1\n",
    "        else:\n",
    "            TDM[file-1][i] = 0\n",
    "        i+=1\n",
    "print(\"Term Document Matrix after filling\\n\",TDM)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"6.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column vector initially\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "x = np.zeros((len(unique_word_set),1));\n",
    "\n",
    "print(\"column vector initially\\n\",x)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"7.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write something for searching  book interesting\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching  \")\n",
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exists then increment the count of that word in column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "query_words = query.split();\n",
    "set_of_unique_words = list(unique_word_set)\n",
    "for unique_word in set_of_unique_words:\n",
    "    if unique_word in query_words:\n",
    "        x[set_of_unique_words.index(unique_word)] = 1\n",
    "    #if unique_word in query_words:\n",
    "    \n",
    "print(x)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"8.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [0.]\n",
      " [2.]]\n",
      "Maximum in resultant is:  2.0\n",
      "Index of maximum resultant is:  2\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "resultant_vector = np.dot(TDM,x)\n",
    "max = np.max(resultant_vector)\n",
    "result = np. where(resultant_vector == max)\n",
    "print(resultant_vector)\n",
    "print(\"Maximum in resultant is: \", max)\n",
    "result = resultant_vector.tolist().index(max)\n",
    "print(\"Index of maximum resultant is: \",result)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"9.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my pen\n",
      "\n",
      "                                                                                                                                                                                                                                          \n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "text_file = open(files_dict[result], 'r')\n",
    "text = text_file.read()\n",
    "print(text)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
